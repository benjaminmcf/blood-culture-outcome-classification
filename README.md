# blood-culture-outcome-classification

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)

An open-source machine learning pipeline for predicting blood culture outcomes from routine haematology parameters generated by Sysmex XN-series analysers.

## Publications

- [Machine learning pipeline for blood culture outcome prediction using Sysmex XN-2000 blood sample results in Western Australia](https://bmcinfectdis.biomedcentral.com/articles/10.1186/s12879-023-08535-y) – BMC Infectious Diseases, 2023
- Evaluation of machine learning pipeline for blood culture outcome prediction on prospectively collected emergency department data (Under peer review)

For a detailed technical description of the methodology, see [METHODS.md](METHODS.md).

## Features

- **Four classifier types:** Logistic Regression (LR), Decision Tree (DT), Random Forest (RF), XGBoost (XG)
- **Two feature spaces:** CBC+DIFF only, or CBC+DIFF+CPD (cell population data)
- **Nested cross-validation:** Unbiased performance estimation with feature selection inside the CV loop
- **Boruta feature selection:** Identifies all-relevant features automatically
- **RFE feature selection:** Recursive feature elimination to a compact feature subset
- **CLI control:** Select models and feature selection methods via command-line flags
- **HTML reports:** Auto-generated training and inference reports with ROC curves and confusion matrices
- **Exportable artifacts:** LR coefficients and DT rules can be deployed without Python
- **Validation mode:** Verify exported artifacts match original model predictions

## Quick Start

```bash
# Clone and install
git clone https://github.com/benjaminmcf/blood-culture-outcome-classification.git
cd blood-culture-outcome-classification

# Using uv (recommended)
uv sync

# Using pip
pip install -e .
```

### Data Preparation

The pipeline reads datasets from the folder specified by `DATA_DIR` in `config.json` (default: `"datasets"`). The repository ships with a ready-to-use example dataset:

**Option A — Use the included example data (recommended for first-time setup):**

The `dataset_examples/` folder is already committed to the repository and contains small synthetic datasets:

- `dataset_examples/training_data.csv` — 319 synthetic training rows
- `dataset_examples/testing_data.csv` — 20 synthetic testing rows

Set `DATA_DIR` in `config.json` to point at it:

```json
{
    "DATA_DIR": "dataset_examples"
}
```

Then run training and inference as normal — no data generation step required.

**Option B — Use your own data:**

Place your CSV files in any folder (absolute or relative to repo root) and update `DATA_DIR` accordingly:

```json
{
    "DATA_DIR": "datasets"
}
```

Expected files:

- `<DATA_DIR>/training_data.csv` — Training data (must contain the target label + feature columns)
- `<DATA_DIR>/testing_data.csv` — Testing/inference data (same column structure)

The required columns are defined in `config.json` (see [Configuration](#configuration) below).

### Train Models

```bash
# Train all models with Boruta feature selection (default)
bcoc-train

# Train specific models without feature selection (fast)
bcoc-train --models dt lr --fs none

# Train all models with all feature selection combinations
bcoc-train --models all --fs all
```

<details>
<summary>Alternative ways to run (without installing)</summary>

```bash
# Using python -m (no install required)
python -m python_scripts.training
python -m python_scripts.training --models dt lr --fs none

# Using uv run (auto-installs ephemerally)
uv run bcoc-train
uv run bcoc-train --models dt lr --fs none
```
</details>

| Flag | Options | Default | Description |
|------|---------|---------|-------------|
| `--models` | `dt`, `rf`, `xg`, `lr`, `all` | `all` | Models to train |
| `--fs` | `boruta`, `rfe`, `none`, `all` | `boruta` | Feature selection method(s) |

### Run Inference

```bash
# Run inference on default test set
bcoc-infer --threshold 0.3

# Run with validation of exported artifacts
bcoc-infer --threshold 0.3 --validate

# Run on a specific input file
bcoc-infer --input path/to/data.csv --threshold 0.3
```

<details>
<summary>Alternative ways to run (without installing)</summary>

```bash
# Using python -m
python -m python_scripts.inference --threshold 0.3

# Using uv run
uv run bcoc-infer --threshold 0.3
```
</details>

| Flag | Description |
|------|-------------|
| `--threshold <float>` | Probability threshold for binary predictions (default: 0.3) |
| `--validate` | Validate LR/DT exported predictions against model objects |
| `--input <path>` | Path to input CSV (default: `datasets/testing_data.csv`) |

## Pipeline Overview

### Training (`bcoc-train`)

1. Loads configuration from `config.json` and training data from `<DATA_DIR>/training_data.csv`
2. Iterates over feature spaces (CBC_DIFF, CBC_DIFF_CPD), models, and feature selection methods
3. Performs **nested cross-validation** with feature selection inside each fold
4. Trains a final model on the full dataset with globally-selected features
5. Saves artifacts and generates an HTML report

**Outputs:**
- `features/` — Selected feature lists (one per model configuration)
- `models/` — Trained model objects (`.sav`) and metadata (`.json`)
- `results/results_cross_validation.csv` — Cross-validation metrics
- `results/training_report.html` — HTML report with metrics table, ROC curves, and confusion matrices

### Inference (`bcoc-infer`)

1. Discovers all trained models in `models/` by reading metadata JSON files
2. For LR: extracts raw-space coefficients and applies them directly
3. For DT: extracts human-readable rules and applies them without the model object
4. For RF/XG: uses saved model objects
5. If ground truth is available, computes performance metrics and generates plots

**Outputs:**
- `predictions/preds_*.csv` — Per-model predictions (`model`, `prob_pos`, `yhat`)
- `predictions/cm_*.csv` — Confusion matrices (when ground truth available)
- `predictions/metrics_summary.csv` — Performance metrics per model
- `predictions/inference_report.html` — HTML report with metrics and visualizations
- `exports/lr_coeffs_*.csv` — LR coefficients for deployment
- `exports/dt_rules_*.txt` / `.json` — DT rules for deployment

### Using Exported LR Coefficients

The LR pipelines export raw-space coefficients so predictions can be made without the model object. Given `exports/lr_coeffs_{config}.csv` with `feature,weight` rows and an `Intercept` row:

1. Compute `z = Σ(weight_i × x_i) + Intercept`
2. Convert to probability: `p = 1 / (1 + exp(-z))`
3. Apply threshold: `yhat = 1 if p ≥ threshold else 0`

Use `--validate` to verify these predictions match the original pipeline.

## Configuration

The pipeline is configured via `config.json`. This allows you to adapt it to **any binary classification problem** without modifying source code.

```json
{
    "RANDOM_STATE": 15,
    "RANDOM_STATE_BORUTA": 42,
    "TARGET_COLUMN": "isPOS",
    "FEATURE_SPACES": {
        "CBC_DIFF": ["WBC(10^9/L)", "RBC(10^12/L)", "..."],
        "CBC_DIFF_CPD": ["WBC(10^9/L)", "...", "[NE-SSC(ch)]", "..."]
    }
}
```

| Key | Required | Default | Description |
|-----|----------|---------|-------------|
| `RANDOM_STATE` | ✅ | — | Seed for model training reproducibility |
| `RANDOM_STATE_BORUTA` | ✅ | — | Seed for Boruta feature selection |
| `DATA_DIR` | ❌ | `datasets` | Folder containing dataset CSVs (absolute or relative to repo root) |
| `TARGET_COLUMN` | ❌ | `isPOS` | Name of the binary target column |
| `FEATURE_SPACES` | ❌ | Built-in defaults | Dict of named feature lists |

### Adapting to Other Problems

To use this pipeline for a different infectious disease classification problem:

1. Set `TARGET_COLUMN` to your binary outcome column name
2. Define your `FEATURE_SPACES` with the relevant clinical variables
3. Set `DATA_DIR` to the folder containing your data files
4. Run `bcoc-train` and `bcoc-infer` as normal

For example, to predict UTI from urinalysis parameters:

```json
{
    "RANDOM_STATE": 42,
    "RANDOM_STATE_BORUTA": 42,
    "TARGET_COLUMN": "isUTI",
    "FEATURE_SPACES": {
        "URINALYSIS": ["WBC_hpf", "nitrites", "leuk_esterase", "bacteria_count"],
        "URINALYSIS_CBC": ["WBC_hpf", "nitrites", "leuk_esterase", "bacteria_count", "WBC", "CRP"]
    }
}
```

## Project Structure

```
├── config.json              # Pipeline configuration (seeds, DATA_DIR, target, feature spaces)
├── pyproject.toml           # Project metadata and dependencies
├── clean.py                 # Remove all pipeline outputs for fresh testing
├── METHODS.md               # Detailed technical methods documentation
├── CONTRIBUTING.md          # Contribution guidelines
├── python_scripts/
│   ├── training.py          # Training entry point (bcoc-train)
│   ├── training_utils.py    # Feature selection, CV, metrics, plotting
│   ├── inference.py         # Inference entry point (bcoc-infer)
│   └── reporting.py         # HTML report generation
├── dataset_examples/        # Committed synthetic example datasets (ready to use)
│   ├── training_data.csv    # 319-row synthetic training set
│   └── testing_data.csv     # 20-row synthetic test set
├── datasets/                # Your own data CSVs (gitignored; set DATA_DIR in config.json)
├── features/                # Selected feature lists (generated)
├── models/                  # Trained model artifacts (generated)
├── results/                 # CV results and training report (generated)
├── predictions/             # Inference outputs and report (generated)
├── exports/                 # LR coefficients, DT rules, validation (generated)
├── notebooks/               # Example notebook for exported model inference
└── tests/                   # Test suite
```

## End-to-End Testing

To test the full pipeline from scratch using the included example data:

```bash
# Ensure config.json has: "DATA_DIR": "dataset_examples"
python clean.py                          # Remove all outputs
bcoc-train --models all --fs none        # Train all models (fast, no feature selection)
bcoc-infer --threshold 0.3               # Run inference on test set
```

### Unit Tests

```bash
pip install -e ".[dev]"
pytest tests/ -v
```

## Citation

If you use this software in your research, please cite:

```bibtex
@software{mcfadden2026bcoc,
  author = {McFadden, Benjamin},
  title = {blood-culture-outcome-classification},
  year = {2026},
  url = {https://github.com/benjaminmcf/blood-culture-outcome-classification}
}
```


## Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## License

This project is licensed under the MIT License — see the [LICENSE](LICENSE) file for details.
