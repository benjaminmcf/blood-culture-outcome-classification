{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c30bc51",
   "metadata": {},
   "source": [
    "# Using Exported Models for Inference (LR & DT)\n",
    "This notebook demonstrates how to run inference using (1) exported logistic regression coefficients and (2) exported decision tree rules. It also shows how to validate those predictions against the original sklearn models (if available) and how to compute and export evaluation artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc25616",
   "metadata": {},
   "source": [
    "## 1) Setup: Imports and Paths\n",
    "We'll import the helper functions from `python_scripts/training_utils.py`, configure logging, and set up paths and a threshold used for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb44369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using threshold: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Imports and Paths\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import sys\n",
    "# Get the path to the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(os.path.dirname(\"notebooks\"), '..'))\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from python_scripts.training_utils import (\n",
    "    project_paths, init_logging, load_model, load_feature_list,\n",
    "    load_lr_coefficients_csv, predict_lr_with_raw_params, predict_with_lr_pipeline,\n",
    "    load_dt_rules_json, predict_with_dt_rules, predict_with_dt_model,\n",
    "    mark_dt_threshold_predictions, render_decision_rules_text,\n",
    "    compute_performance_metrics, export_confusion_matrix_csv, compare_predictions,\n",
    " )\n",
    "\n",
    "# Initialize logging\n",
    "init_logging()\n",
    "paths = project_paths()\n",
    "\n",
    "# --- Configure file locations ---\n",
    "# You can update these to match your specific artifacts.\n",
    "# Dataset: use testing if present, else fall back to training\n",
    "data_csv = paths[\"datasets\"] / \"testing_sysmex_deduped.csv\"\n",
    "if not data_csv.exists():\n",
    "    data_csv = paths[\"datasets\"] / \"training_data.csv\"\n",
    "\n",
    "# Feature list (txt) used for both LR and DT models\n",
    "# Example naming: 'lr_CBC_DIFF_1_boruta.txt' or 'dt_CBC_DIFF_1_boruta.txt'\n",
    "# Pick one consistent with your exported artifacts:\n",
    "feature_space = \"CBC_DIFF\"\n",
    "weight = \"1\"\n",
    "fsm = \"boruta\"\n",
    "features_txt_lr = paths[\"features\"] / f\"lr_{feature_space}_{weight}_{fsm}.txt\"\n",
    "features_txt_dt = paths[\"features\"] / f\"dt_{feature_space}_{weight}_{fsm}.txt\"\n",
    "\n",
    "# Exported artifacts\n",
    "lr_coeffs_csv = paths[\"root\"] / \"exports\" / f\"lr_coeffs_{feature_space}_{weight}_{fsm}.csv\"\n",
    "lr_pipeline_pkl = paths[\"models\"] / f\"lr_{feature_space}_{weight}_{fsm}.sav\"\n",
    "dt_rules_json = paths[\"root\"] / \"exports\" / f\"dt_rules_{feature_space}_{weight}_{fsm}.json\"\n",
    "dt_model_pkl = paths[\"models\"] / f\"dt_{feature_space}_{weight}_{fsm}.sav\"\n",
    "\n",
    "# Outputs\n",
    "out_dir = paths[\"root\"] / \"notebook_outputs\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Classification threshold (applies to both LR and DT)\n",
    "threshold = 0.3\n",
    "print(\"Using threshold:\", threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3cfae4",
   "metadata": {},
   "source": [
    "## 2) Load Inference Dataset\n",
    "We'll load the dataset and align it to the expected feature set. If the labels column `isPOS` exists, we'll keep it for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebf58aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: /Users/benjaminmcfadden/Documents/REPOS/blood-culture-outcome-classification/datasets/testing_sysmex_deduped.csv with shape (318, 431)\n",
      "LR features txt: True DT features txt: True\n",
      "X_lr shape: (318, 17) | X_dt shape: (318, 17)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(data_csv)\n",
    "print(\"Loaded:\", data_csv, \"with shape\", df.shape)\n",
    "\n",
    "# Load feature orders\n",
    "feat_order_lr = load_feature_list(features_txt_lr) if features_txt_lr.exists() else None\n",
    "feat_order_dt = load_feature_list(features_txt_dt) if features_txt_dt.exists() else None\n",
    "print(\"LR features txt:\", features_txt_lr.exists(), \"DT features txt:\", features_txt_dt.exists())\n",
    "\n",
    "# Determine target label if present\n",
    "target_col = \"isPOS\" if \"isPOS\" in df.columns else None\n",
    "y = df[target_col].astype(int) if target_col else None\n",
    "\n",
    "# Align and coerce feature matrices\n",
    "def align_X(df_in: pd.DataFrame, feat_order: list[str]) -> pd.DataFrame:\n",
    "    missing = [c for c in feat_order if c not in df_in.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing required columns for inference: {missing}\")\n",
    "    X = df_in[feat_order].copy().astype(float)\n",
    "    # Drop rows with missing values in required columns\n",
    "    X = X.dropna(subset=feat_order)\n",
    "    return X\n",
    "\n",
    "X_lr = align_X(df, feat_order_lr) if feat_order_lr else None\n",
    "X_dt = align_X(df, feat_order_dt) if feat_order_dt else None\n",
    "print(\"X_lr shape:\", None if X_lr is None else X_lr.shape, \"| X_dt shape:\", None if X_dt is None else X_dt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023bf700",
   "metadata": {},
   "source": [
    "## 3) Load Logistic Regression Coefficients\n",
    "Load the raw-space coefficients and intercept exported from the training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3241bbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded LR coeffs for 17 features\n"
     ]
    }
   ],
   "source": [
    "# Load LR coefficients CSV\n",
    "if not lr_coeffs_csv.exists():\n",
    "    raise FileNotFoundError(f\"Missing LR coefficients CSV: {lr_coeffs_csv}\")\n",
    "feat_order_lr_csv, weights_raw, intercept_raw = load_lr_coefficients_csv(lr_coeffs_csv)\n",
    "print(\"Loaded LR coeffs for\", len(feat_order_lr_csv), \"features\")\n",
    "\n",
    "# Ensure X_lr aligns with the order in the coefficients file\n",
    "if X_lr is None:\n",
    "    X_lr = align_X(df, feat_order_lr_csv)\n",
    "else:\n",
    "    # Reorder to match coefficients if necessary\n",
    "    X_lr = X_lr[feat_order_lr_csv].copy()\n",
    "X_lr = X_lr.astype(float)\n",
    "\n",
    "# Note: scoring uses z = Xw + b and p = 1/(1+exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5448da8",
   "metadata": {},
   "source": [
    "## 4) Predict with Logistic Coefficients (Raw Space)\n",
    "Run logistic regression inference using the exported coefficients. If labels are available, compute metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b3b7daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR predictions: 318\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba_lr</th>\n",
       "      <th>preds_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.534530</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.435435</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.366797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.140166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.778879</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.418181</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.221608</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.552619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.360949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proba_lr  preds_lr\n",
       "0  0.534530         1\n",
       "1  0.435435         1\n",
       "2  0.067803         0\n",
       "3  0.366797         1\n",
       "4  0.140166         0\n",
       "5  0.778879         1\n",
       "6  0.418181         1\n",
       "7  0.221608         0\n",
       "8  0.552619         1\n",
       "9  0.360949         1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR metrics: {\n",
      "  \"n\": 318.0,\n",
      "  \"tp\": 26.0,\n",
      "  \"tn\": 72.0,\n",
      "  \"fp\": 220.0,\n",
      "  \"fn\": 0.0,\n",
      "  \"accuracy\": 0.3081761006289308,\n",
      "  \"recall\": 1.0,\n",
      "  \"precision\": 0.10569105691056911,\n",
      "  \"roc_auc\": 0.7837197049525817,\n",
      "  \"balanced_accuracy\": 0.6232876712328768,\n",
      "  \"specificity\": 0.2465753424657534,\n",
      "  \"j_stat\": 0.24657534246575352,\n",
      "  \"f2\": 0.3714285714285714,\n",
      "  \"lr_plus\": 1.3272727272727272,\n",
      "  \"lr_minus\": 0.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Predict with LR coefficients\n",
    "proba_lr, preds_lr = predict_lr_with_raw_params(\n",
    "    X_lr, feat_order_lr_csv, weights_raw, intercept_raw, threshold=threshold\n",
    " )\n",
    "print(\"LR predictions:\", len(preds_lr))\n",
    "\n",
    "# Show head\n",
    "display(pd.DataFrame({\n",
    "    \"proba_lr\": proba_lr[:10],\n",
    "    \"preds_lr\": preds_lr[:10],\n",
    "}))\n",
    "\n",
    "# Metrics if labels available\n",
    "if y is not None:\n",
    "    # Ensure y is aligned to X rows (drop rows that were removed due to NA)\n",
    "    y_aligned = y.loc[X_lr.index].values.astype(int)\n",
    "    metrics_lr = compute_performance_metrics(y_aligned, preds_lr, proba_lr)\n",
    "    print(\"LR metrics:\", json.dumps(metrics_lr, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5875d4",
   "metadata": {},
   "source": [
    "## 5) Validate LR Coefficient Inference vs Pipeline\n",
    "If the original LR pipeline is available, we can compare the coefficient-based predictions to the pipeline outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a28a6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR compare (coeffs vs pipeline): {\n",
      "  \"preds_equal\": true,\n",
      "  \"mismatch_count\": 0,\n",
      "  \"prob_all_close\": true,\n",
      "  \"prob_max_abs_diff\": 6.994405055138486e-15,\n",
      "  \"prob_mean_abs_diff\": 1.4172761544872476e-15,\n",
      "  \"count\": 318,\n",
      "  \"prob_tol\": 1e-09\n",
      "}\n",
      "LR pipeline metrics:\n",
      "{\n",
      "  \"n\": 318.0,\n",
      "  \"tp\": 26.0,\n",
      "  \"tn\": 72.0,\n",
      "  \"fp\": 220.0,\n",
      "  \"fn\": 0.0,\n",
      "  \"accuracy\": 0.3081761006289308,\n",
      "  \"recall\": 1.0,\n",
      "  \"precision\": 0.10569105691056911,\n",
      "  \"roc_auc\": 0.7837197049525817,\n",
      "  \"balanced_accuracy\": 0.6232876712328768,\n",
      "  \"specificity\": 0.2465753424657534,\n",
      "  \"j_stat\": 0.24657534246575352,\n",
      "  \"f2\": 0.3714285714285714,\n",
      "  \"lr_plus\": 1.3272727272727272,\n",
      "  \"lr_minus\": 0.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Validate vs pipeline (if available)\n",
    "if lr_pipeline_pkl.exists():\n",
    "    pipeline = load_model(lr_pipeline_pkl)\n",
    "    proba_skl, preds_skl = predict_with_lr_pipeline(pipeline, X_lr, threshold=threshold)\n",
    "    cmp = compare_predictions(proba_lr, preds_lr, proba_skl, preds_skl, prob_tol=1e-9)\n",
    "    print(\"LR compare (coeffs vs pipeline):\", json.dumps(cmp, indent=2))\n",
    "    if y is not None:\n",
    "        y_aligned = y.loc[X_lr.index].values.astype(int)\n",
    "        print(\"LR pipeline metrics:\")\n",
    "        print(json.dumps(compute_performance_metrics(y_aligned, preds_skl, proba_skl), indent=2))\n",
    "else:\n",
    "    print(\"LR pipeline pickle not found:\", lr_pipeline_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8510a0d5",
   "metadata": {},
   "source": [
    "## 6) Load Decision Tree Rules\n",
    "Load the exported JSON rules and (optionally) annotate leaves with threshold-based predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e21c0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DT rules. Saved threshold in file: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Load DT rules JSON\n",
    "if not dt_rules_json.exists():\n",
    "    raise FileNotFoundError(f\"Missing DT rules JSON: {dt_rules_json}\")\n",
    "tree_dict, saved_thr = load_dt_rules_json(dt_rules_json)\n",
    "print(\"Loaded DT rules. Saved threshold in file:\", saved_thr)\n",
    "\n",
    "# Optionally mark leaves using current threshold\n",
    "tree_dict = mark_dt_threshold_predictions(tree_dict, threshold)\n",
    "\n",
    "# Feature order for DT is described by the features txt (as exported at training time)\n",
    "if X_dt is None:\n",
    "    # Fall back to LR feature order if DT features file is missing but rules reference the same names\n",
    "    # Otherwise, ensure you create a DT features file matching your model artifacts.\n",
    "    if feat_order_lr is None:\n",
    "        raise FileNotFoundError(\"DT features list not found. Ensure a matching features txt exists.\")\n",
    "    X_dt = align_X(df, feat_order_lr)\n",
    "feature_order_dt = list(X_dt.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ee90a3",
   "metadata": {},
   "source": [
    "## 7) Predict with Decision Tree Rules\n",
    "Infer probabilities and labels from the rules; thresholding converts probabilities to binary predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d1d8397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT rule-based predictions: 318\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba_dt_rules</th>\n",
       "      <th>preds_dt_thresh</th>\n",
       "      <th>preds_dt_leaf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.433409</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.433409</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.207423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.433409</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.207423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.761530</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.433409</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.207423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.433409</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.207423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proba_dt_rules  preds_dt_thresh  preds_dt_leaf\n",
       "0        0.433409                1              0\n",
       "1        0.433409                1              0\n",
       "2        0.207423                0              0\n",
       "3        0.433409                1              0\n",
       "4        0.207423                0              0\n",
       "5        0.761530                1              1\n",
       "6        0.433409                1              0\n",
       "7        0.207423                0              0\n",
       "8        0.433409                1              0\n",
       "9        0.207423                0              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT rule metrics: {\n",
      "  \"n\": 318.0,\n",
      "  \"tp\": 25.0,\n",
      "  \"tn\": 101.0,\n",
      "  \"fp\": 191.0,\n",
      "  \"fn\": 1.0,\n",
      "  \"accuracy\": 0.39622641509433965,\n",
      "  \"recall\": 0.9615384615384616,\n",
      "  \"precision\": 0.11574074074074074,\n",
      "  \"roc_auc\": 0.7907665964172813,\n",
      "  \"balanced_accuracy\": 0.6537144362486829,\n",
      "  \"specificity\": 0.3458904109589041,\n",
      "  \"j_stat\": 0.3074288724973657,\n",
      "  \"f2\": 0.39062500000000006,\n",
      "  \"lr_plus\": 1.4699959726137735,\n",
      "  \"lr_minus\": 0.11119573495811112\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Predict using the rules\n",
    "proba_dt_rules, preds_dt_leaf = predict_with_dt_rules(X_dt, list(X_dt.columns), tree_dict)\n",
    "preds_dt_thresh = (proba_dt_rules >= threshold).astype(int)\n",
    "print(\"DT rule-based predictions:\", len(preds_dt_thresh))\n",
    "\n",
    "# Show head\n",
    "display(pd.DataFrame({\n",
    "    \"proba_dt_rules\": proba_dt_rules[:10],\n",
    "    \"preds_dt_thresh\": preds_dt_thresh[:10],\n",
    "    \"preds_dt_leaf\": preds_dt_leaf[:10],\n",
    "}))\n",
    "\n",
    "# Metrics if labels available\n",
    "if y is not None:\n",
    "    y_aligned_dt = y.loc[X_dt.index].values.astype(int)\n",
    "    metrics_dt = compute_performance_metrics(y_aligned_dt, preds_dt_thresh, proba_dt_rules)\n",
    "    print(\"DT rule metrics:\", json.dumps(metrics_dt, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af75e325",
   "metadata": {},
   "source": [
    "## 8) Validate Decision Tree Rule Inference vs Model\n",
    "If the sklearn DT model is available, compare rule-based predictions to the model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74d2169e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT compare (rules vs model): {\n",
      "  \"preds_equal\": true,\n",
      "  \"mismatch_count\": 0,\n",
      "  \"prob_all_close\": true,\n",
      "  \"prob_max_abs_diff\": 2.3425705819590803e-14,\n",
      "  \"prob_mean_abs_diff\": 9.92802974701554e-15,\n",
      "  \"count\": 318,\n",
      "  \"prob_tol\": 1e-09\n",
      "}\n",
      "DT sklearn metrics:\n",
      "{\n",
      "  \"n\": 318.0,\n",
      "  \"tp\": 25.0,\n",
      "  \"tn\": 101.0,\n",
      "  \"fp\": 191.0,\n",
      "  \"fn\": 1.0,\n",
      "  \"accuracy\": 0.39622641509433965,\n",
      "  \"recall\": 0.9615384615384616,\n",
      "  \"precision\": 0.11574074074074074,\n",
      "  \"roc_auc\": 0.7907665964172813,\n",
      "  \"balanced_accuracy\": 0.6537144362486829,\n",
      "  \"specificity\": 0.3458904109589041,\n",
      "  \"j_stat\": 0.3074288724973657,\n",
      "  \"f2\": 0.39062500000000006,\n",
      "  \"lr_plus\": 1.4699959726137735,\n",
      "  \"lr_minus\": 0.11119573495811112\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Validate vs DT model (if available)\n",
    "if dt_model_pkl.exists():\n",
    "    dt_model = load_model(dt_model_pkl)\n",
    "    proba_dt_skl, preds_dt_skl = predict_with_dt_model(dt_model, X_dt, threshold=threshold)\n",
    "    cmp_dt = compare_predictions(proba_dt_rules, preds_dt_thresh, proba_dt_skl, preds_dt_skl, prob_tol=1e-9)\n",
    "    print(\"DT compare (rules vs model):\", json.dumps(cmp_dt, indent=2))\n",
    "    if y is not None:\n",
    "        y_aligned_dt = y.loc[X_dt.index].values.astype(int)\n",
    "        print(\"DT sklearn metrics:\")\n",
    "        print(json.dumps(compute_performance_metrics(y_aligned_dt, preds_dt_skl, proba_dt_skl), indent=2))\n",
    "else:\n",
    "    print(\"DT model pickle not found:\", dt_model_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28323fd5",
   "metadata": {},
   "source": [
    "## 9) Render and Inspect Decision Rules Text\n",
    "You can render human-readable rules from the JSON tree and inspect leaf annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44f347f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if NEUT%(%) <= 85.850002:\n",
      "  if MONO#(10^9/L) <= 0.275000:\n",
      "    if MONO%(%) <= 2.450000:\n",
      "      => leaf: pred_class=1 prob_pos=0.811 pred_thresh=1 counts=[0.18853345077471192, 0.811466549225284]\n",
      "    else:  # MONO%(%) > 2.450000\n",
      "      => leaf: pred_class=1 prob_pos=0.503 pred_thresh=1 counts=[0.4972500675462207, 0.5027499324537767]\n",
      "  else:  # MONO#(10^9/L) > 0.275000\n",
      "    if NLR <= 5.838250:\n",
      "      => leaf: pred_class=0 prob_pos=0.207 pred_thresh=0 counts=[0.792576528759268, 0.2074234712407495]\n",
      "    else:  # NLR > 5.838250\n",
      "      => leaf: pred_class=0 prob_pos=0.433 pred_thresh=1 counts=[0.5665907537584309, 0.43340924624160176]\n",
      "else:  # NEUT%(%) > 85.850002\n",
      "  if NEUT%(%) <= 90.750000:\n",
      "    if RDW-CV(%) <= 12.250000:\n",
      "      => leaf: pred_class=0 prob_pos=0.253 pred_thresh=0 counts=[0.7469662921348313, 0.25303370786516866]\n",
      "    else:  # RDW-CV(%) > 12.250000\n",
      "      => leaf: pred_class=1 prob_pos=0.655 pred_thresh=1 counts=[0.34548842861025225, 0.6545115713897834]\n",
      "  else:  # NEUT%(%) > 90.750000\n",
      "    if MONO%(%) <= 1.650000:\n",
      "      => leaf: pred_class=1 prob_pos=0.888 pred_thresh=1 counts=[0.11247521914634398, 0.8875247808536536]\n",
      "    else:  # MONO%(%) > 1.650000\n",
      "      => leaf: pred_class=1 prob_pos=0.762 pred_thresh=1 counts=[0.23846974362078371, 0.7615302563792233]\n"
     ]
    }
   ],
   "source": [
    "# Render rules text\n",
    "lines = render_decision_rules_text(tree_dict)\n",
    "print(\"\\n\".join(lines[:200]))  # print the first ~200 lines for brevity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea80ff1",
   "metadata": {},
   "source": [
    "## 10) Compute and Export Evaluation Artifacts\n",
    "If labels are available, we can export confusion matrices and a combined results CSV for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d5a782d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported confusion matrices to: /Users/benjaminmcfadden/Documents/REPOS/blood-culture-outcome-classification/notebook_outputs\n",
      "Wrote: /Users/benjaminmcfadden/Documents/REPOS/blood-culture-outcome-classification/notebook_outputs/inference_results_lr_dt.csv\n"
     ]
    }
   ],
   "source": [
    "# Export artifacts (optional)\n",
    "if y is not None:\n",
    "    y_lr = y.loc[X_lr.index].values.astype(int)\n",
    "    y_dt = y.loc[X_dt.index].values.astype(int)\n",
    "    # Confusion matrices\n",
    "    export_confusion_matrix_csv(out_dir / \"cm_lr_from_coeffs.csv\", y_lr, preds_lr.astype(int))\n",
    "    export_confusion_matrix_csv(out_dir / \"cm_dt_from_rules.csv\", y_dt, preds_dt_thresh.astype(int))\n",
    "    print(\"Exported confusion matrices to:\", out_dir)\n",
    "\n",
    "    # Combined results CSV\n",
    "    df_out = pd.DataFrame({\n",
    "        \"index\": X_lr.index,\n",
    "        \"proba_lr\": proba_lr,\n",
    "        \"preds_lr\": preds_lr,\n",
    "        \"proba_dt_rules\": proba_dt_rules,\n",
    "        \"preds_dt_thresh\": preds_dt_thresh,\n",
    "    })\n",
    "    if target_col:\n",
    "        df_out[target_col] = y.loc[X_lr.index].values.astype(int)\n",
    "    df_out.to_csv(out_dir / \"inference_results_lr_dt.csv\", index=False)\n",
    "    print(\"Wrote:\", out_dir / \"inference_results_lr_dt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab426f8",
   "metadata": {},
   "source": [
    "## 11) Optional: Batch Scoring Functions (LR and DT)\n",
    "Reusable helpers for batch scoring from CSV input files. Update paths as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6044caee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined batch scoring helpers: score_with_lr_coeffs, score_with_dt_rules\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Tuple\n",
    "\n",
    "def score_with_lr_coeffs(input_csv: Path, features_txt: Path, coeffs_csv: Path, out_csv: Path, threshold: float = 0.3, target_col: Optional[str] = \"isPOS\") -> Tuple[pd.DataFrame, Optional[dict]]:\n",
    "    df_in = pd.read_csv(input_csv)\n",
    "    feat_order = load_feature_list(features_txt)\n",
    "    X = df_in[feat_order].copy().astype(float).dropna(subset=feat_order)\n",
    "    y_local = df_in[target_col].astype(int).loc[X.index].values if (target_col and target_col in df_in.columns) else None\n",
    "    feats, weights, intercept = load_lr_coefficients_csv(coeffs_csv)\n",
    "    proba, preds = predict_lr_with_raw_params(X[feats], feats, weights, intercept, threshold=threshold)\n",
    "    out_df = pd.DataFrame({\"index\": X.index, \"proba_lr\": proba, \"preds_lr\": preds})\n",
    "    out_df.to_csv(out_csv, index=False)\n",
    "    metrics = compute_performance_metrics(y_local, preds, proba) if y_local is not None else None\n",
    "    return out_df, metrics\n",
    "\n",
    "def score_with_dt_rules(input_csv: Path, features_txt: Path, rules_json: Path, out_csv: Path, threshold: float = 0.3, target_col: Optional[str] = \"isPOS\") -> Tuple[pd.DataFrame, Optional[dict]]:\n",
    "    df_in = pd.read_csv(input_csv)\n",
    "    feat_order = load_feature_list(features_txt)\n",
    "    X = df_in[feat_order].copy().astype(float).dropna(subset=feat_order)\n",
    "    y_local = df_in[target_col].astype(int).loc[X.index].values if (target_col and target_col in df_in.columns) else None\n",
    "    tree, saved_thr = load_dt_rules_json(rules_json)\n",
    "    tree = mark_dt_threshold_predictions(tree, threshold)\n",
    "    proba, preds_leaf = predict_with_dt_rules(X, feat_order, tree)\n",
    "    preds = (proba >= threshold).astype(int)\n",
    "    out_df = pd.DataFrame({\"index\": X.index, \"proba_dt_rules\": proba, \"preds_dt_thresh\": preds, \"preds_dt_leaf\": preds_leaf})\n",
    "    out_df.to_csv(out_csv, index=False)\n",
    "    metrics = compute_performance_metrics(y_local, preds, proba) if y_local is not None else None\n",
    "    return out_df, metrics\n",
    "\n",
    "print(\"Defined batch scoring helpers: score_with_lr_coeffs, score_with_dt_rules\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blood-culture-outcome-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
